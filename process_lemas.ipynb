{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/EscUpmPolit_p.gif \"UPM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use nltk, we should download first the lexical resources we are going to use. We can updated them later. For this, you need:\n",
    "* install nltk. Execute 'pip install nltk'\n",
    "* import nltk\n",
    "* Run *nltk.download()* (the first time we use it). A window will appear. You should select just the corpus 'book' and press download.\n",
    "If you inspect the window, you can get an overview of available lexical resources (corpora, lexicons and grammars). For example, you can find some relevant sentiment lexicons in corpora (SentiWordNet, Sentence Polarity Dataset, Vader, Opinion Lexicon or VADER Sentiment Lexicon). Don't forget to close the window once the data has been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl\n",
    "# pip install nltk\n",
    "# pip install pandas\n",
    "# pip install \"pandas[excel]\"\n",
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('universal_tagset')\n",
    "#nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        filename, _ = os.path.splitext(os.path.basename(file_path))\n",
    "    return text, filename\n",
    "\n",
    "\n",
    "# lemaArray => [(id, word, tag_universal, tag_upenn)]\n",
    "\n",
    "def merge_postagged(lemaArray1, lemaArray2):\n",
    "    result_array = []\n",
    "    for i in range(len(lemaArray1)):\n",
    "        key = i\n",
    "        word = lemaArray1[i][0]\n",
    "        value = lemaArray1[i][1]\n",
    "        value2 = lemaArray2[i][1]\n",
    "        result_array.append((key, word, value, value2))\n",
    "\n",
    "    # Convert the merged dictionary back to a list of tuples\n",
    "    return result_array\n",
    "\n",
    "def generateDfLemas(lemaArray):\n",
    "    columns = ['Index', 'Word', 'POS_Universal', 'POS_UPenn']\n",
    "    return pd.DataFrame(lemaArray, columns=columns)\n",
    "    \n",
    "def merge_words_and_count(dfLemas):\n",
    "    return dfLemas.groupby(['Word', 'POS_Universal', 'POS_UPenn']).size().reset_index(name='Count').sort_values(by='Count', ascending=False)\n",
    "\n",
    "\n",
    "def generate_text_from_lemma_array(lemaArray):\n",
    "    return [\" \".join(w for _, w, _, _ in lemaArray)][0]\n",
    "\n",
    "def save_data_text(folder, name, text):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    file_path = os.path.join(folder, name + '.txt')\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)    \n",
    "\n",
    "def save_data_frame(folder, name, df):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    file_path = os.path.join(folder, name + '.xlsx')\n",
    "    df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text, filename = read_text_from_file('./94.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some', 'people', 'prefer', 'to', 'live', 'in', 'places', 'that', 'have', 'the', 'same', 'weather', 'or', 'climate', 'all', 'year', 'long', '.', 'Others', 'like', 'to', 'live', 'in', 'areas', 'where', 'the', 'weather', 'changes', 'several', 'times', 'a', 'year', '.', 'Which', 'do', 'you', 'prefer', '?', 'Use', 'specific', 'reasons', 'and', 'examples', 'to', 'support', 'your', 'choice', '.', 'I', 'was', 'born', 'in', 'a', 'part', 'of', 'the', 'world', 'where', 'the', 'climate', 'has', 'four', 'seasons', 'and', 'I', 'learnt', 'how', 'much', 'beauty', 'each', 'of', 'these', 'periods', 'can', 'bring', 'to', 'the', 'environments', 'and', 'our', 'lives', '.', 'I', 'prefer', 'to', 'live', 'in', 'an', 'area', 'where', 'the', 'weather', 'changes', 'several', 'times', 'a', 'year', '.', 'Although', 'sometimes', 'I', 'experience', 'difficulties', 'in', 'the', 'cold', 'winters', 'because', 'of', 'my', 'bad', 'tolerance', 'to', 'low', 'temperatures', ',', 'I', 'can', 'not', 'imagine', 'the', 'Christmas', 'without', 'the', 'white', 'snow', 'making', 'the', 'whole', 'world', 'to', 'look', 'like', 'the', 'pictures', 'from', 'a', 'fairy', 'tale', 'book', '.', 'There', 'is', 'so', 'much', 'beauty', 'that', 'each', 'season', 'comes', 'with', 'that', 'I', 'do', 'not', 'think', 'I', 'can', 'live', 'in', 'a', 'place', 'where', 'the', 'climate', 'is', 'the', 'same', 'all', 'year', 'long', '.', 'I', 'might', 'like', 'going', 'in', 'those', 'places', 'for', 'some', 'weeks', 'in', 'winter', 'but', 'not', 'for', 'a', 'longer', 'time', '.', 'If', 'I', 'were', 'to', 'live', 'in', 'such', 'a', 'place', 'for', 'a', 'life-', 'time', ',', 'I', 'would', 'miss', 'the', 'spring', 'when', 'the', 'whole', 'nature', 'wakes', 'up', '.', 'I', 'would', 'miss', 'all', 'the', 'wonderful', 'spring', 'colors', ',', 'the', 'new', 'buds', ',', 'the', 'first', 'grass', 'that', 'comes', 'after', 'the', 'gray', 'winter', ',', 'the', 'trees', 'blooming', ',', 'and', 'the', 'birds', 'that', 'are', 'coming', 'back', 'from', 'warmer', 'places', 'where', 'they', 'lived', 'during', 'winter', '.', 'The', 'spring', 'is', 'my', 'favorite', 'season', ',', 'but', 'I', 'love', 'and', 'know', 'to', 'cherish', 'the', 'others', 'as', 'well', '.', 'Talking', 'about', 'colors', ',', 'the', 'fall', 'is', 'the', 'next', 'on', 'my', 'list', ',', 'with', 'all', 'those', 'reddish', ',', 'yellowish', 'and', 'brownish', 'hues', 'that', 'cover', 'both', 'the', 'leaves', 'and', 'the', 'earth', '.', 'The', 'ripe', 'harvests', ',', 'the', 'crops', 'waiting', 'to', 'be', 'gathered', 'are', 'things', 'that', 'bring', 'joy', 'and', 'satisfaction', 'in', 'fall', '.', 'The', 'summer', 'has', 'its', 'own', 'beauty', 'and', 'in', 'that', 'period', 'of', 'the', 'year', 'the', 'holiday', 'flavor', 'is', 'in', 'the', 'air', '.', 'In', 'places', 'with', 'temperate', 'climate', 'the', 'vegetation', 'is', 'abundant', '.', 'The', 'days', 'are', 'sunny', 'and', 'bright', '.', 'Living', 'in', 'a', 'place', 'with', 'the', 'same', 'climate', 'all', 'year', 'around', 'would', 'be', 'very', 'difficult', ',', 'as', 'I', 'could', 'not', 'enjoy', 'and', 'cherish', 'the', 'wonderful', 'things', 'that', 'occur', 'every', 'time', 'a', 'new', 'season', 'arrive', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Some', 'DET', 'DT'),\n",
       " (1, 'people', 'NOUN', 'NNS'),\n",
       " (2, 'prefer', 'VERB', 'VBP'),\n",
       " (3, 'to', 'PRT', 'TO'),\n",
       " (4, 'live', 'VERB', 'VB'),\n",
       " (5, 'in', 'ADP', 'IN'),\n",
       " (6, 'places', 'NOUN', 'NNS'),\n",
       " (7, 'that', 'DET', 'WDT'),\n",
       " (8, 'have', 'VERB', 'VBP'),\n",
       " (9, 'the', 'DET', 'DT'),\n",
       " (10, 'same', 'ADJ', 'JJ'),\n",
       " (11, 'weather', 'NOUN', 'NN'),\n",
       " (12, 'or', 'CONJ', 'CC'),\n",
       " (13, 'climate', 'NOUN', 'NN'),\n",
       " (14, 'all', 'DET', 'DT'),\n",
       " (15, 'year', 'NOUN', 'NN'),\n",
       " (16, 'long', 'ADV', 'RB'),\n",
       " (17, '.', '.', '.'),\n",
       " (18, 'Others', 'NOUN', 'NNS'),\n",
       " (19, 'like', 'ADP', 'IN'),\n",
       " (20, 'to', 'PRT', 'TO'),\n",
       " (21, 'live', 'VERB', 'VB'),\n",
       " (22, 'in', 'ADP', 'IN'),\n",
       " (23, 'areas', 'NOUN', 'NNS'),\n",
       " (24, 'where', 'ADV', 'WRB'),\n",
       " (25, 'the', 'DET', 'DT'),\n",
       " (26, 'weather', 'NOUN', 'NN'),\n",
       " (27, 'changes', 'VERB', 'VBZ'),\n",
       " (28, 'several', 'ADJ', 'JJ'),\n",
       " (29, 'times', 'NOUN', 'NNS'),\n",
       " (30, 'a', 'DET', 'DT'),\n",
       " (31, 'year', 'NOUN', 'NN'),\n",
       " (32, '.', '.', '.'),\n",
       " (33, 'Which', 'NOUN', 'NNP'),\n",
       " (34, 'do', 'VERB', 'VBP'),\n",
       " (35, 'you', 'PRON', 'PRP'),\n",
       " (36, 'prefer', 'VERB', 'VB'),\n",
       " (37, '?', '.', '.'),\n",
       " (38, 'Use', 'NOUN', 'NNP'),\n",
       " (39, 'specific', 'ADJ', 'JJ'),\n",
       " (40, 'reasons', 'NOUN', 'NNS'),\n",
       " (41, 'and', 'CONJ', 'CC'),\n",
       " (42, 'examples', 'NOUN', 'NNS'),\n",
       " (43, 'to', 'PRT', 'TO'),\n",
       " (44, 'support', 'VERB', 'VB'),\n",
       " (45, 'your', 'PRON', 'PRP$'),\n",
       " (46, 'choice', 'NOUN', 'NN'),\n",
       " (47, '.', '.', '.'),\n",
       " (48, 'I', 'PRON', 'PRP'),\n",
       " (49, 'was', 'VERB', 'VBD'),\n",
       " (50, 'born', 'VERB', 'VBN'),\n",
       " (51, 'in', 'ADP', 'IN'),\n",
       " (52, 'a', 'DET', 'DT'),\n",
       " (53, 'part', 'NOUN', 'NN'),\n",
       " (54, 'of', 'ADP', 'IN'),\n",
       " (55, 'the', 'DET', 'DT'),\n",
       " (56, 'world', 'NOUN', 'NN'),\n",
       " (57, 'where', 'ADV', 'WRB'),\n",
       " (58, 'the', 'DET', 'DT'),\n",
       " (59, 'climate', 'NOUN', 'NN'),\n",
       " (60, 'has', 'VERB', 'VBZ'),\n",
       " (61, 'four', 'NUM', 'CD'),\n",
       " (62, 'seasons', 'NOUN', 'NNS'),\n",
       " (63, 'and', 'CONJ', 'CC'),\n",
       " (64, 'I', 'PRON', 'PRP'),\n",
       " (65, 'learnt', 'VERB', 'VBP'),\n",
       " (66, 'how', 'ADV', 'WRB'),\n",
       " (67, 'much', 'ADJ', 'JJ'),\n",
       " (68, 'beauty', 'NOUN', 'NN'),\n",
       " (69, 'each', 'DET', 'DT'),\n",
       " (70, 'of', 'ADP', 'IN'),\n",
       " (71, 'these', 'DET', 'DT'),\n",
       " (72, 'periods', 'NOUN', 'NNS'),\n",
       " (73, 'can', 'VERB', 'MD'),\n",
       " (74, 'bring', 'VERB', 'VB'),\n",
       " (75, 'to', 'PRT', 'TO'),\n",
       " (76, 'the', 'DET', 'DT'),\n",
       " (77, 'environments', 'NOUN', 'NNS'),\n",
       " (78, 'and', 'CONJ', 'CC'),\n",
       " (79, 'our', 'PRON', 'PRP$'),\n",
       " (80, 'lives', 'NOUN', 'NNS'),\n",
       " (81, '.', '.', '.'),\n",
       " (82, 'I', 'PRON', 'PRP'),\n",
       " (83, 'prefer', 'VERB', 'VBP'),\n",
       " (84, 'to', 'PRT', 'TO'),\n",
       " (85, 'live', 'VERB', 'VB'),\n",
       " (86, 'in', 'ADP', 'IN'),\n",
       " (87, 'an', 'DET', 'DT'),\n",
       " (88, 'area', 'NOUN', 'NN'),\n",
       " (89, 'where', 'ADV', 'WRB'),\n",
       " (90, 'the', 'DET', 'DT'),\n",
       " (91, 'weather', 'NOUN', 'NN'),\n",
       " (92, 'changes', 'VERB', 'VBZ'),\n",
       " (93, 'several', 'ADJ', 'JJ'),\n",
       " (94, 'times', 'NOUN', 'NNS'),\n",
       " (95, 'a', 'DET', 'DT'),\n",
       " (96, 'year', 'NOUN', 'NN'),\n",
       " (97, '.', '.', '.'),\n",
       " (98, 'Although', 'ADP', 'IN'),\n",
       " (99, 'sometimes', 'ADV', 'RB'),\n",
       " (100, 'I', 'PRON', 'PRP'),\n",
       " (101, 'experience', 'VERB', 'VBP'),\n",
       " (102, 'difficulties', 'NOUN', 'NNS'),\n",
       " (103, 'in', 'ADP', 'IN'),\n",
       " (104, 'the', 'DET', 'DT'),\n",
       " (105, 'cold', 'ADJ', 'JJ'),\n",
       " (106, 'winters', 'NOUN', 'NNS'),\n",
       " (107, 'because', 'ADP', 'IN'),\n",
       " (108, 'of', 'ADP', 'IN'),\n",
       " (109, 'my', 'PRON', 'PRP$'),\n",
       " (110, 'bad', 'ADJ', 'JJ'),\n",
       " (111, 'tolerance', 'NOUN', 'NN'),\n",
       " (112, 'to', 'PRT', 'TO'),\n",
       " (113, 'low', 'ADJ', 'JJ'),\n",
       " (114, 'temperatures', 'NOUN', 'NNS'),\n",
       " (115, ',', '.', ','),\n",
       " (116, 'I', 'PRON', 'PRP'),\n",
       " (117, 'can', 'VERB', 'MD'),\n",
       " (118, 'not', 'ADV', 'RB'),\n",
       " (119, 'imagine', 'VERB', 'VB'),\n",
       " (120, 'the', 'DET', 'DT'),\n",
       " (121, 'Christmas', 'NOUN', 'NNP'),\n",
       " (122, 'without', 'ADP', 'IN'),\n",
       " (123, 'the', 'DET', 'DT'),\n",
       " (124, 'white', 'ADJ', 'JJ'),\n",
       " (125, 'snow', 'NOUN', 'NN'),\n",
       " (126, 'making', 'VERB', 'VBG'),\n",
       " (127, 'the', 'DET', 'DT'),\n",
       " (128, 'whole', 'ADJ', 'JJ'),\n",
       " (129, 'world', 'NOUN', 'NN'),\n",
       " (130, 'to', 'PRT', 'TO'),\n",
       " (131, 'look', 'VERB', 'VB'),\n",
       " (132, 'like', 'ADP', 'IN'),\n",
       " (133, 'the', 'DET', 'DT'),\n",
       " (134, 'pictures', 'NOUN', 'NNS'),\n",
       " (135, 'from', 'ADP', 'IN'),\n",
       " (136, 'a', 'DET', 'DT'),\n",
       " (137, 'fairy', 'ADJ', 'JJ'),\n",
       " (138, 'tale', 'NOUN', 'NN'),\n",
       " (139, 'book', 'NOUN', 'NN'),\n",
       " (140, '.', '.', '.'),\n",
       " (141, 'There', 'DET', 'EX'),\n",
       " (142, 'is', 'VERB', 'VBZ'),\n",
       " (143, 'so', 'ADV', 'RB'),\n",
       " (144, 'much', 'ADJ', 'JJ'),\n",
       " (145, 'beauty', 'NOUN', 'NN'),\n",
       " (146, 'that', 'ADP', 'IN'),\n",
       " (147, 'each', 'DET', 'DT'),\n",
       " (148, 'season', 'NOUN', 'NN'),\n",
       " (149, 'comes', 'VERB', 'VBZ'),\n",
       " (150, 'with', 'ADP', 'IN'),\n",
       " (151, 'that', 'DET', 'DT'),\n",
       " (152, 'I', 'PRON', 'PRP'),\n",
       " (153, 'do', 'VERB', 'VBP'),\n",
       " (154, 'not', 'ADV', 'RB'),\n",
       " (155, 'think', 'VERB', 'VB'),\n",
       " (156, 'I', 'PRON', 'PRP'),\n",
       " (157, 'can', 'VERB', 'MD'),\n",
       " (158, 'live', 'VERB', 'VB'),\n",
       " (159, 'in', 'ADP', 'IN'),\n",
       " (160, 'a', 'DET', 'DT'),\n",
       " (161, 'place', 'NOUN', 'NN'),\n",
       " (162, 'where', 'ADV', 'WRB'),\n",
       " (163, 'the', 'DET', 'DT'),\n",
       " (164, 'climate', 'NOUN', 'NN'),\n",
       " (165, 'is', 'VERB', 'VBZ'),\n",
       " (166, 'the', 'DET', 'DT'),\n",
       " (167, 'same', 'ADJ', 'JJ'),\n",
       " (168, 'all', 'DET', 'DT'),\n",
       " (169, 'year', 'NOUN', 'NN'),\n",
       " (170, 'long', 'ADV', 'RB'),\n",
       " (171, '.', '.', '.'),\n",
       " (172, 'I', 'PRON', 'PRP'),\n",
       " (173, 'might', 'VERB', 'MD'),\n",
       " (174, 'like', 'VERB', 'VB'),\n",
       " (175, 'going', 'VERB', 'VBG'),\n",
       " (176, 'in', 'ADP', 'IN'),\n",
       " (177, 'those', 'DET', 'DT'),\n",
       " (178, 'places', 'NOUN', 'NNS'),\n",
       " (179, 'for', 'ADP', 'IN'),\n",
       " (180, 'some', 'DET', 'DT'),\n",
       " (181, 'weeks', 'NOUN', 'NNS'),\n",
       " (182, 'in', 'ADP', 'IN'),\n",
       " (183, 'winter', 'NOUN', 'NN'),\n",
       " (184, 'but', 'CONJ', 'CC'),\n",
       " (185, 'not', 'ADV', 'RB'),\n",
       " (186, 'for', 'ADP', 'IN'),\n",
       " (187, 'a', 'DET', 'DT'),\n",
       " (188, 'longer', 'ADJ', 'JJR'),\n",
       " (189, 'time', 'NOUN', 'NN'),\n",
       " (190, '.', '.', '.'),\n",
       " (191, 'If', 'ADP', 'IN'),\n",
       " (192, 'I', 'PRON', 'PRP'),\n",
       " (193, 'were', 'VERB', 'VBD'),\n",
       " (194, 'to', 'PRT', 'TO'),\n",
       " (195, 'live', 'VERB', 'VB'),\n",
       " (196, 'in', 'ADP', 'IN'),\n",
       " (197, 'such', 'ADJ', 'JJ'),\n",
       " (198, 'a', 'DET', 'DT'),\n",
       " (199, 'place', 'NOUN', 'NN'),\n",
       " (200, 'for', 'ADP', 'IN'),\n",
       " (201, 'a', 'DET', 'DT'),\n",
       " (202, 'life-', 'ADJ', 'JJ'),\n",
       " (203, 'time', 'NOUN', 'NN'),\n",
       " (204, ',', '.', ','),\n",
       " (205, 'I', 'PRON', 'PRP'),\n",
       " (206, 'would', 'VERB', 'MD'),\n",
       " (207, 'miss', 'VERB', 'VB'),\n",
       " (208, 'the', 'DET', 'DT'),\n",
       " (209, 'spring', 'NOUN', 'NN'),\n",
       " (210, 'when', 'ADV', 'WRB'),\n",
       " (211, 'the', 'DET', 'DT'),\n",
       " (212, 'whole', 'ADJ', 'JJ'),\n",
       " (213, 'nature', 'NOUN', 'NN'),\n",
       " (214, 'wakes', 'VERB', 'VBZ'),\n",
       " (215, 'up', 'PRT', 'RP'),\n",
       " (216, '.', '.', '.'),\n",
       " (217, 'I', 'PRON', 'PRP'),\n",
       " (218, 'would', 'VERB', 'MD'),\n",
       " (219, 'miss', 'VERB', 'VB'),\n",
       " (220, 'all', 'DET', 'PDT'),\n",
       " (221, 'the', 'DET', 'DT'),\n",
       " (222, 'wonderful', 'ADJ', 'JJ'),\n",
       " (223, 'spring', 'NOUN', 'NN'),\n",
       " (224, 'colors', 'NOUN', 'NNS'),\n",
       " (225, ',', '.', ','),\n",
       " (226, 'the', 'DET', 'DT'),\n",
       " (227, 'new', 'ADJ', 'JJ'),\n",
       " (228, 'buds', 'NOUN', 'NN'),\n",
       " (229, ',', '.', ','),\n",
       " (230, 'the', 'DET', 'DT'),\n",
       " (231, 'first', 'ADJ', 'JJ'),\n",
       " (232, 'grass', 'NOUN', 'NN'),\n",
       " (233, 'that', 'DET', 'WDT'),\n",
       " (234, 'comes', 'VERB', 'VBZ'),\n",
       " (235, 'after', 'ADP', 'IN'),\n",
       " (236, 'the', 'DET', 'DT'),\n",
       " (237, 'gray', 'ADJ', 'JJ'),\n",
       " (238, 'winter', 'NOUN', 'NN'),\n",
       " (239, ',', '.', ','),\n",
       " (240, 'the', 'DET', 'DT'),\n",
       " (241, 'trees', 'NOUN', 'NNS'),\n",
       " (242, 'blooming', 'NOUN', 'NN'),\n",
       " (243, ',', '.', ','),\n",
       " (244, 'and', 'CONJ', 'CC'),\n",
       " (245, 'the', 'DET', 'DT'),\n",
       " (246, 'birds', 'NOUN', 'NNS'),\n",
       " (247, 'that', 'DET', 'WDT'),\n",
       " (248, 'are', 'VERB', 'VBP'),\n",
       " (249, 'coming', 'VERB', 'VBG'),\n",
       " (250, 'back', 'ADV', 'RB'),\n",
       " (251, 'from', 'ADP', 'IN'),\n",
       " (252, 'warmer', 'NOUN', 'NN'),\n",
       " (253, 'places', 'NOUN', 'NNS'),\n",
       " (254, 'where', 'ADV', 'WRB'),\n",
       " (255, 'they', 'PRON', 'PRP'),\n",
       " (256, 'lived', 'VERB', 'VBD'),\n",
       " (257, 'during', 'ADP', 'IN'),\n",
       " (258, 'winter', 'NOUN', 'NN'),\n",
       " (259, '.', '.', '.'),\n",
       " (260, 'The', 'DET', 'DT'),\n",
       " (261, 'spring', 'NOUN', 'NN'),\n",
       " (262, 'is', 'VERB', 'VBZ'),\n",
       " (263, 'my', 'PRON', 'PRP$'),\n",
       " (264, 'favorite', 'ADJ', 'JJ'),\n",
       " (265, 'season', 'NOUN', 'NN'),\n",
       " (266, ',', '.', ','),\n",
       " (267, 'but', 'CONJ', 'CC'),\n",
       " (268, 'I', 'PRON', 'PRP'),\n",
       " (269, 'love', 'VERB', 'VBP'),\n",
       " (270, 'and', 'CONJ', 'CC'),\n",
       " (271, 'know', 'VERB', 'VBP'),\n",
       " (272, 'to', 'PRT', 'TO'),\n",
       " (273, 'cherish', 'VERB', 'VB'),\n",
       " (274, 'the', 'DET', 'DT'),\n",
       " (275, 'others', 'NOUN', 'NNS'),\n",
       " (276, 'as', 'ADP', 'IN'),\n",
       " (277, 'well', 'ADV', 'RB'),\n",
       " (278, '.', '.', '.'),\n",
       " (279, 'Talking', 'VERB', 'VBG'),\n",
       " (280, 'about', 'ADP', 'IN'),\n",
       " (281, 'colors', 'NOUN', 'NNS'),\n",
       " (282, ',', '.', ','),\n",
       " (283, 'the', 'DET', 'DT'),\n",
       " (284, 'fall', 'NOUN', 'NN'),\n",
       " (285, 'is', 'VERB', 'VBZ'),\n",
       " (286, 'the', 'DET', 'DT'),\n",
       " (287, 'next', 'ADJ', 'JJ'),\n",
       " (288, 'on', 'ADP', 'IN'),\n",
       " (289, 'my', 'PRON', 'PRP$'),\n",
       " (290, 'list', 'NOUN', 'NN'),\n",
       " (291, ',', '.', ','),\n",
       " (292, 'with', 'ADP', 'IN'),\n",
       " (293, 'all', 'DET', 'PDT'),\n",
       " (294, 'those', 'DET', 'DT'),\n",
       " (295, 'reddish', 'ADJ', 'JJ'),\n",
       " (296, ',', '.', ','),\n",
       " (297, 'yellowish', 'ADJ', 'JJ'),\n",
       " (298, 'and', 'CONJ', 'CC'),\n",
       " (299, 'brownish', 'ADJ', 'JJ'),\n",
       " (300, 'hues', 'NOUN', 'NNS'),\n",
       " (301, 'that', 'DET', 'WDT'),\n",
       " (302, 'cover', 'VERB', 'VBP'),\n",
       " (303, 'both', 'DET', 'DT'),\n",
       " (304, 'the', 'DET', 'DT'),\n",
       " (305, 'leaves', 'NOUN', 'NNS'),\n",
       " (306, 'and', 'CONJ', 'CC'),\n",
       " (307, 'the', 'DET', 'DT'),\n",
       " (308, 'earth', 'NOUN', 'NN'),\n",
       " (309, '.', '.', '.'),\n",
       " (310, 'The', 'DET', 'DT'),\n",
       " (311, 'ripe', 'ADJ', 'JJ'),\n",
       " (312, 'harvests', 'NOUN', 'NNS'),\n",
       " (313, ',', '.', ','),\n",
       " (314, 'the', 'DET', 'DT'),\n",
       " (315, 'crops', 'NOUN', 'NNS'),\n",
       " (316, 'waiting', 'VERB', 'VBG'),\n",
       " (317, 'to', 'PRT', 'TO'),\n",
       " (318, 'be', 'VERB', 'VB'),\n",
       " (319, 'gathered', 'VERB', 'VBN'),\n",
       " (320, 'are', 'VERB', 'VBP'),\n",
       " (321, 'things', 'NOUN', 'NNS'),\n",
       " (322, 'that', 'ADP', 'IN'),\n",
       " (323, 'bring', 'VERB', 'VBG'),\n",
       " (324, 'joy', 'NOUN', 'NN'),\n",
       " (325, 'and', 'CONJ', 'CC'),\n",
       " (326, 'satisfaction', 'NOUN', 'NN'),\n",
       " (327, 'in', 'ADP', 'IN'),\n",
       " (328, 'fall', 'NOUN', 'NN'),\n",
       " (329, '.', '.', '.'),\n",
       " (330, 'The', 'DET', 'DT'),\n",
       " (331, 'summer', 'NOUN', 'NN'),\n",
       " (332, 'has', 'VERB', 'VBZ'),\n",
       " (333, 'its', 'PRON', 'PRP$'),\n",
       " (334, 'own', 'ADJ', 'JJ'),\n",
       " (335, 'beauty', 'NOUN', 'NN'),\n",
       " (336, 'and', 'CONJ', 'CC'),\n",
       " (337, 'in', 'ADP', 'IN'),\n",
       " (338, 'that', 'DET', 'DT'),\n",
       " (339, 'period', 'NOUN', 'NN'),\n",
       " (340, 'of', 'ADP', 'IN'),\n",
       " (341, 'the', 'DET', 'DT'),\n",
       " (342, 'year', 'NOUN', 'NN'),\n",
       " (343, 'the', 'DET', 'DT'),\n",
       " (344, 'holiday', 'NOUN', 'NN'),\n",
       " (345, 'flavor', 'NOUN', 'NN'),\n",
       " (346, 'is', 'VERB', 'VBZ'),\n",
       " (347, 'in', 'ADP', 'IN'),\n",
       " (348, 'the', 'DET', 'DT'),\n",
       " (349, 'air', 'NOUN', 'NN'),\n",
       " (350, '.', '.', '.'),\n",
       " (351, 'In', 'ADP', 'IN'),\n",
       " (352, 'places', 'NOUN', 'NNS'),\n",
       " (353, 'with', 'ADP', 'IN'),\n",
       " (354, 'temperate', 'ADJ', 'JJ'),\n",
       " (355, 'climate', 'NOUN', 'NN'),\n",
       " (356, 'the', 'DET', 'DT'),\n",
       " (357, 'vegetation', 'NOUN', 'NN'),\n",
       " (358, 'is', 'VERB', 'VBZ'),\n",
       " (359, 'abundant', 'ADJ', 'JJ'),\n",
       " (360, '.', '.', '.'),\n",
       " (361, 'The', 'DET', 'DT'),\n",
       " (362, 'days', 'NOUN', 'NNS'),\n",
       " (363, 'are', 'VERB', 'VBP'),\n",
       " (364, 'sunny', 'ADJ', 'JJ'),\n",
       " (365, 'and', 'CONJ', 'CC'),\n",
       " (366, 'bright', 'ADJ', 'JJ'),\n",
       " (367, '.', '.', '.'),\n",
       " (368, 'Living', 'VERB', 'VBG'),\n",
       " (369, 'in', 'ADP', 'IN'),\n",
       " (370, 'a', 'DET', 'DT'),\n",
       " (371, 'place', 'NOUN', 'NN'),\n",
       " (372, 'with', 'ADP', 'IN'),\n",
       " (373, 'the', 'DET', 'DT'),\n",
       " (374, 'same', 'ADJ', 'JJ'),\n",
       " (375, 'climate', 'NOUN', 'NN'),\n",
       " (376, 'all', 'DET', 'DT'),\n",
       " (377, 'year', 'NOUN', 'NN'),\n",
       " (378, 'around', 'ADV', 'RB'),\n",
       " (379, 'would', 'VERB', 'MD'),\n",
       " (380, 'be', 'VERB', 'VB'),\n",
       " (381, 'very', 'ADV', 'RB'),\n",
       " (382, 'difficult', 'ADJ', 'JJ'),\n",
       " (383, ',', '.', ','),\n",
       " (384, 'as', 'ADP', 'IN'),\n",
       " (385, 'I', 'PRON', 'PRP'),\n",
       " (386, 'could', 'VERB', 'MD'),\n",
       " (387, 'not', 'ADV', 'RB'),\n",
       " (388, 'enjoy', 'VERB', 'VB'),\n",
       " (389, 'and', 'CONJ', 'CC'),\n",
       " (390, 'cherish', 'VERB', 'VB'),\n",
       " (391, 'the', 'DET', 'DT'),\n",
       " (392, 'wonderful', 'ADJ', 'JJ'),\n",
       " (393, 'things', 'NOUN', 'NNS'),\n",
       " (394, 'that', 'DET', 'WDT'),\n",
       " (395, 'occur', 'VERB', 'VBP'),\n",
       " (396, 'every', 'DET', 'DT'),\n",
       " (397, 'time', 'NOUN', 'NN'),\n",
       " (398, 'a', 'DET', 'DT'),\n",
       " (399, 'new', 'ADJ', 'JJ'),\n",
       " (400, 'season', 'NOUN', 'NN'),\n",
       " (401, 'arrive', 'NOUN', 'NN'),\n",
       " (402, '.', '.', '.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_postagged_universal = pos_tag(word_tokenize(text), tagset='universal')\n",
    "text_postagged_upenn = pos_tag(word_tokenize(text))\n",
    "text_postagged = merge_postagged(text_postagged_universal, text_postagged_upenn)\n",
    "\n",
    "text_postagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS_Universal</th>\n",
       "      <th>POS_UPenn</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>i</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>CONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>holiday</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>how</td>\n",
       "      <td>ADV</td>\n",
       "      <td>WRB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>hue</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>your</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word POS_Universal POS_UPenn  Count\n",
       "149      the           DET        DT     37\n",
       "80        in           ADP        IN     14\n",
       "77         i          PRON       PRP     13\n",
       "10       and          CONJ        CC     11\n",
       "1          a           DET        DT     10\n",
       "..       ...           ...       ...    ...\n",
       "72      have          VERB       VBP      1\n",
       "74   holiday          NOUN        NN      1\n",
       "75       how           ADV       WRB      1\n",
       "76       hue          NOUN       NNS      1\n",
       "186     your          PRON      PRP$      1\n",
       "\n",
       "[187 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization without punctuations and lower\n",
    "pos_mapping = {'NOUN': 'n', 'ADJ': 'a', 'VERB': 'v', 'ADV': 'r', 'ADP': 'n', 'CONJ': 'n', \n",
    "               'PRON': 'n', 'NUM': 'n', 'DET':'n', 'PRT':'n', 'X': 'n', 'ADJ_SAT': 's' }\n",
    "\n",
    "wordnet = WordNetLemmatizer()\n",
    "lemmas_without_punctuation_lower = [(id, wordnet.lemmatize(w, pos=pos_mapping[tag_universal]).lower(), tag_universal, tag_upenn)  for (id, w,tag_universal, tag_upenn)  in text_postagged if tag_universal in pos_mapping.keys()]\n",
    "text_lemmas_without_punctuation_lower  = generate_text_from_lemma_array(lemmas_without_punctuation_lower)\n",
    "\n",
    "# print(lemmas_without_punctuation_lower)\n",
    "# print(text_lemmas_without_punctuation_lower)\n",
    "\n",
    "df_lemmas_without_punctuation_lower = generateDfLemas(lemmas_without_punctuation_lower)\n",
    "df_lemmas_without_punctuation_lower_unique_count = merge_words_and_count(df_lemmas_without_punctuation_lower)\n",
    "\n",
    "\n",
    "save_data_text('./'+filename, filename+'_1_'+'text_lemmas_without_punctuation_lower', text_lemmas_without_punctuation_lower)\n",
    "save_data_frame('./'+filename, filename+'_1_'+'df_lemmas_without_punctuation_lower', df_lemmas_without_punctuation_lower)\n",
    "save_data_frame('./'+filename, filename+'_1_'+'df_lemmas_without_punctuation_lower_unique_count', df_lemmas_without_punctuation_lower_unique_count)\n",
    "\n",
    "df_lemmas_without_punctuation_lower_unique_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS_Universal</th>\n",
       "      <th>POS_UPenn</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>climate</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>live</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>place</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>winter</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>first</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>favorite</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>fairy</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>experience</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>yellowish</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word POS_Universal POS_UPenn  Count\n",
       "129        year          NOUN        NN      6\n",
       "23      climate          NOUN        NN      5\n",
       "63         live          VERB        VB      5\n",
       "86        place          NOUN       NNS      4\n",
       "123      winter          NOUN        NN      3\n",
       "..          ...           ...       ...    ...\n",
       "43        first           ADJ        JJ      1\n",
       "42     favorite           ADJ        JJ      1\n",
       "40        fairy           ADJ        JJ      1\n",
       "39   experience          VERB       VBP      1\n",
       "130   yellowish           ADJ        JJ      1\n",
       "\n",
       "[131 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - without stop words\n",
    "stoplist = stopwords.words('english')\n",
    "#print(stoplist)\n",
    "\n",
    "\n",
    "lemmas_without_stop_words = [lemma for lemma in lemmas_without_punctuation_lower if lemma[1] not in stoplist]\n",
    "text_lemmas_without_stop_words = generate_text_from_lemma_array(lemmas_without_stop_words)\n",
    "\n",
    "# print(lemmas_without_stop_words)\n",
    "# print(text_lemmas_without_stop_words)\n",
    "\n",
    "df_lemmas_without_stop_words = generateDfLemas(lemmas_without_stop_words)\n",
    "df_lemmas_without_stop_words_unique_count = merge_words_and_count(df_lemmas_without_stop_words)\n",
    "\n",
    "\n",
    "save_data_text('./'+filename, filename+'_2_'+'text_lemmas_without_stop_words', text_lemmas_without_stop_words)\n",
    "save_data_frame('./'+filename, filename+'_2_'+'df_lemmas_without_stop_words', df_lemmas_without_stop_words)\n",
    "save_data_frame('./'+filename, filename+'_2_'+'df_lemmas_without_stop_words_unique_count', df_lemmas_without_stop_words_unique_count)\n",
    "\n",
    "df_lemmas_without_stop_words_unique_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS_Universal</th>\n",
       "      <th>POS_UPenn</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>live</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>climate</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>place</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>beauty</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>flavor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>first</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>favorite</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fairy</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>yellowish</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word POS_Universal POS_UPenn  Count\n",
       "124       year          NOUN        NN      6\n",
       "59        live          VERB        VB      5\n",
       "22     climate          NOUN        NN      5\n",
       "82       place          NOUN       NNS      4\n",
       "9       beauty          NOUN        NN      3\n",
       "..         ...           ...       ...    ...\n",
       "42      flavor          NOUN        NN      1\n",
       "41       first           ADJ        JJ      1\n",
       "40    favorite           ADJ        JJ      1\n",
       "38       fairy           ADJ        JJ      1\n",
       "125  yellowish           ADJ        JJ      1\n",
       "\n",
       "[126 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - only nouns, adjectives, verbs, and adverbs\n",
    "\n",
    "pos_mapping = {'NOUN': 'n', 'X': 'n', 'ADJ': 'a', 'VERB': 'v', 'ADV': 'r', 'ADJ_SAT': 's' }\n",
    "\n",
    "lemmas_only_noun_verb_adj_adv = [lemma for lemma in lemmas_without_stop_words if lemma[2] in pos_mapping.keys()]\n",
    "text_lemmas_only_noun_verb_adj_adv = generate_text_from_lemma_array(lemmas_without_stop_words)\n",
    "\n",
    "# print(lemmas_only_noun_verb_adj_adv)\n",
    "# print(text_lemmas_only_noun_verb_adj_adv)\n",
    "\n",
    "\n",
    "df_lemmas_only_noun_verb_adj_adv = generateDfLemas(lemmas_only_noun_verb_adj_adv)\n",
    "df_lemmas_only_noun_verb_adj_adv_unique_count = merge_words_and_count(df_lemmas_only_noun_verb_adj_adv)\n",
    "\n",
    "\n",
    "save_data_text('./'+filename, filename+'_3_'+'text_lemmas_only_noun_verb_adj_adv', text_lemmas_only_noun_verb_adj_adv)\n",
    "save_data_frame('./'+filename, filename+'_3_'+'df_lemmas_only_noun_verb_adj_adv', df_lemmas_only_noun_verb_adj_adv)\n",
    "save_data_frame('./'+filename, filename+'_3_'+'df_lemmas_only_noun_verb_adj_adv_unique_count', df_lemmas_only_noun_verb_adj_adv_unique_count)\n",
    "\n",
    "df_lemmas_only_noun_verb_adj_adv_unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_text('./'+filename, filename+'_0_original', text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8e7cfe2d745659bfe6a719605e99dcaa2596559737aa354b5ffde34ee9104f30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
